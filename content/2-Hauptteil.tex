\chapter{Grundlagen}
\label{sec:Grundlagen}

Um Textstrukturen in größeren Sammlungen mit Hilfe von Topic Models visualisieren zu können benötigt man Verfahren, die diese Topic Models von den gesammelten Dokumenten erstellen und geeignete Darstellungsformen für diese Topic Models. Wie Topic Models erstellt werden, soll im Rahmen dieser Arbeit nur kurz beschrieben werden. Der Fokus dieser Arbeit liegt auf den Methoden, die Topic Models aufbereiten und darstellen können. 


\section{Latent Dirichlet Allocation}
\label{sec:LDA}

\subsection{Topic Model Verfahren im Überblick}
\label{sec:Überblick}
Das erste Verfahren für eine Abstraktion von Texten war das Latent semantic Analysis von Deerwester und Dumais\cite{Deerwester.1990}. Darauf aufbauend wurde das Verfahren probabilistic Latent Semantic Indexing von Hofmann eingeführt\cite{Hofmann.1999}. 
Aufgrund einiger Unzulänglichkeiten in dem Verfahren wurde von Blei das Verfahren der Latent Dirichlet Allocation vorgestellt\cite{Blei.2003}. 

\subsection{Vorgehen bei der Latent Dirichlet Allocation}
\label{sec:Vorgehen}

Bei der Latent Dirichlet Allocation handelt es sich um ein statistisches Modell eines Textkorpus. Die zugrundeliegende Idee ist, dass Dokumente als Kombination aus Themen dargestellt werden können, wobei jedes Thema als Verteilung über die im Text vorhandenen Wörter angesehen werden kann. Das LDA-Modell dient nicht nur der Verarbeitung von Texten, es kann auch in anderen Bereichen angewendet werden. Wörter sind die Basiseinheit der Daten als Teil eines Wörterbuchs und werden mit einem Einheitsvektor beschrieben. Ein Dokument ist eine Abfolge von Wörtern und ein Korpus ist eine Sammlung von Dokumenten. \cite[995 f.]{Blei.2003}
\\Die Themen sind $\beta_{1:K}$ bei den jedes $\beta_{k}$ eine Verteilung über das Vokabular des Korpus ist. $\theta_{d}$ ist das Verhältnis der Themen für das dte Dokument, wobei $\theta_{d,k}$ der Anteil von Thema d an Dokument k ist. Die dem dten Dokument zugewiesenen Themen sind $z_{d}$, wobei $z_{d,n}$ das dem nten Wort zugewiesene Thema in Dokument d ist. Die beobachteten Wörter in Dokument d sind $w_{d}$ und $w_{d,n}$ ist das nte Wort aus dem Dokument d. Alle $w_{d,n}$ sind Teil des fixierten Vokabulars \cite[80]{Blei.2012}. Abbildung 2.1 ist die graphische Darstellung des statistischen Prozesses. 
\\Die Parameter $\beta_{1:K}$ und $\theta_{d}$ sind von besonderem Interesse.\cite[7]{Steyvers.2007} Diese beiden Parameter umfassen die versteckten Parameter, die das Verfahren herausgefunden hat. $\beta_{1:K}$ umfasst alle Topics mit den jeweiligen Wörtern und den gewichten der jeweiligen Wörter. $\theta_{d}$ gibt die Verteilung der Themen zu einem bestimmten Dokument d an.

\emph{was ist eine Dirichlet Verteilung}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/2-Hauptteil/LDA_Model}
	\caption[Latent Dirichlet Allocation]{Eigene Adaption der Darstellung von \cite[81]{Blei.2012}. Bei der Abbildung handelt es sich um ein graphisch probabilistisches Modell des LDA }
\end{figure}

Das zentrale Problem bei dem LDA ist das Berechnen der Verteilungen von $\beta$ und $\theta$. Diese Verteilungen lassen sich nicht berechnen. Sie müssen über eine näherungsweise Inferenz bestimmt werden. Dazu stehen verschiedene Algorithmen zur Verfügung. Zu diesen Algorithmen gehören die Variationsinferenz, wie sie von Blei \cite[1003]{Blei.2003} vorgeschlagen wird oder einer Form der Markov Chain Monte Carlo, dem Gibbs Sampling, dass von Griffiths und Steyvers \cite{Griffiths.2002,Griffiths.2004,Griffiths.2003} auf das LDA angwendet wird
Hier könnte ich die einzelnen Inferenz noch näher beschreiben.
\\Essentiell für die Verwendung eines bestimmten Topic Models ist die Qualität der Ergebnisse. Für die Überprüfung der Qualität gibt es verschiedene Verfahren. Ein Verfahren umfasst die Analyse von Topics mit Hilfe von Kennzahlen, wie sie in Wallach et al. \cite{Wallach.2009} vorgestellt wird. %nachteil des Verfahrens
Eine andere Herangehensweise an die Evaluation von Topic Models stellt Chang et al. vor. Das vorgestellte Verfahren misst die Qualität von Topic Models in zwei Dimensionen. Die erste Dimension ist die Qualität der Topics an sich. Gemessen wird dies, indem überprüft wird, ob alle Wörter die eine hohe Wahrscheinlichkeit in einem Topic erhalten haben auch dem daraus folgenden Thema zugehören. Die zweite Dimension überprüft, ob die gefundenen Themen eines Dokuments mit dem von einer Person empfundenen Sinn übereinstimmen. Verglichen wurden das probabilistic latent semantic indexing (pLSI), das latent Dirichlet allocation (LDA)und das correlated topic model (CTM)\cite{Blei.2006}. Das Ergebnis der qualitativen Studie war, dass das LDA model die genauesten Ergebnisse liefert. 
Des weiteren wurden Methoden entwickelt um diese Prozesse zu automatisieren.\cite{Lau.2014}


\section{Darstellungsverfahren}
\label{sec:Darstellungsverfahren}

Da Topic Models eine Zusammenfassung des Korpus darstellen, muss sich auch die visuelle Aufbereitung des Topic Models an dem Korpus orientieren. Der Korpus bestimmt gibt Aufschluss über die Ziele die mit der Erstellung des Topic Models verfolgt werden. Mögliche Verwendungen für ein Topic Model sind die Erschließung eines Korpus, die Darstellung der Themen eines Korpus oder eine Analyse der Struktur des Korpus. In den vergangenen Jahren wurde eine Reihe von Artikel veröffentlicht in den Ansätze erarbeitet wurden, wie Topic Models visuell dargestellt werden können. In den folgenden Abschnitten erfolgt eine Diskussion dieser Arbeiten.

\subsection{Graphische Darstellung der Topic Models}
\label{sec:graphische_darstellung}

Zunächst sollen jedoch Möglichkeiten die Daten direkt, ohne eine weitere Aufbereitung mit Hilfe von Standarddiagrammen dargestellt werden. Mit Standarddiagrammen wird hier auf die gängigen Darstellungsformen für statistische Daten, wie sie in den Python Softwarebibliotheken matplotlib\footnote{http://matplotlib.org}, seaborn\footnote{https://web.stanford.edu/~mwaskom/software/seaborn/index.html} oder prettyplotlib\footnote{http://blog.olgabotvinnik.com/prettyplotlib/} zu finden sind. Wobei Seaborn und prettyplotlib auf matplotlib aufbauen. 
\\Bei $\beta$ und $\Theta$ handelt es sich jeweils um Matrizen, in den die Werte für die Wahrscheinlichkeit der Wörter und den Anteil der Themen vorkommen. Die Grafik in Abbildung 2.2 gibt Aufschluss wie diese Matrizen bei dem LDA Topic Modell in Verbindung stehen.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/2-Hauptteil/matrix_factorization}
	\caption[Matrix Zerlegung bei einem LDA Topic Modell]{Matrix Zerlegung bei einem LDA Topic Modell}
\end{figure}

Da es sich bei beiden Dimensionen um Matrizen handelt, kommt für die Darstellung der Werte nur eine Form in Frage, die alle Werte dieser Matrix darstellen kann. Eine Darstellungsform, die diese Kriterien erfüllt ist die Heatmap. Bei einer Heatmap werden auf der x-Achse oder der y-Achse die Zeilen beziehungsweise die Spalten abgetragen.  Die Farbe des Feldes an einer beliebigen Stelle kodiert den Wert, des x/y Paares der Matrix. Ein Beispiel für eine solche Heatmap ist in Abbildung 2.3 aufgeführt. Das Beispiel wurde mit der seaborn Bibliothek und einem Musterskript, dass auf der Webseite\footnote{https://web.stanford.edu/~mwaskom/software/seaborn/examples/many\_pairwise\_correlations.html}  zur Verfügung gestellt wurde erstellt.

\begin{figure}
	\centering
	\includegraphics[width=0.75\textwidth]{images/2-Hauptteil/Heatmap_example}
	\caption[Beispiel einer Heatmap]{Beispiel einer Heatmap}
\end{figure}

In dieser Abbildung sind die Achsen jeweils mit den Buchstaben von A bis Z beschriftet. Möchte man eine der Verteilung in einer solchen Heatmap darstellen, muss man zunächst festlegen auf welcher Achse die Zeile bzw. die Spalte abgetragen wird. Anschaulich wird das, wenn man es an dem Beispiel $\Theta$ darstellt. In der Matrix von $\Theta$ werden die Dokumente des Korpus in den Spalten und die Topics in den Zeilen dargestellt. In der Matrix ist der jeweilige Anteil des Topics am Dokument. \emph{ist der nicht in Summe 1?} Bei dieser Konstellation wird ein Problem mit dieser Darstellungsform ersichtlich. Für große Corpora, mit einer hohen Anzahl an Dokumenten wird diese Darstellungsform schnell unübersichtlich. Dies gilt ebenfalls für die Darstellung von $\beta$, da die Matrix das gesamte Vokabular aller Dokumente umfasst. Dadurch wird  die Darstellung schon für kleinere Textkörper unübersichtlich. 
\\Diese Form der Darstellung gibt jedoch nur Auskunft über die Zusammensetzung der Themen bzw. der Dokumente. Eine Analyse einer höher aggregierten Ebene des Korpus ist dadurch nicht möglich. Um eine solche Analyse zu ermöglichen wird eine andere Form der Darstellung benötigt. 
Dafür bietet sich ein Netzwerk an, dass die Verbindungen im Textkorpus darstellt. 
\\Ein Netzwerk besteht aus Knoten und Kanten. Jeder Knoten stellt ein Objekt im Netzwerk dar. Die Kanten verbinden die Knoten und bilden das Netz zwischen den Knoten. Über eine Gewichtung können Kanten auch die Beziehung zwischen zwei Knoten näher beschreiben. So eine Gewichtung kann auf verschiedene Weisen in einem Netzwerk dargestellt werden. Durch eine dicke oder eine sehr kurze Kante zwischen zwei Knoten kann eine besonders enge Verbindung der Knoten angedeutet werden\cite[9 ff.]{Golbeck.2013}. \emph{Hier könnte evt. noch etwas zur Repräsentation von Netzwerken stehen}
\\Möchte man mit Python ein Netzwerk aus einem Topic Modell erstellen, kann man verschiedene Bibliotheken verwenden. Die Bibliothek, um Netzwerkrepräsentationen mit Python zu erstellen nennt sich NetworkX\footnote{https://networkx.readthedocs.org/en/stable/index.html}. Es besteht diese direkt in seinem Code einzubinden oder sie als Teil der Tethne\footnote{https://diging.github.io/tethne/api/index.html} Bibiliothek zu verwenden. Beide Bibliotheken sind jedoch nicht in der Lage, Netzwerke direkt zu zeichnen. NetworkX verwendet die Bibliotheken PyGraphviz\footnote{https://pygraphviz.github.io/} und Matplotlib um Netzwerke zu erstellen. In Tethne erstellte Netzwerke können mit Cytoscape\footnote{http://www.cytoscape.org/} oder Gephi\footnote{https://gephi.org/} visualisiert werden. 

Im folgenden erfolgt die Beschreibung des Ablaufs, wie aus einem Topic Model mit Hilfe von Tethne ein Netzwerk erstellt werden kann.\\ Eine Beschreibung wie ein Netzwerk aus einem Topic Modell erstellt werden kann findet sich in einem Tutorial auf der Webseite von tethne. Abbildung 2.4 zeigt ein semanisches Netzwerk. Bei diesem Netzwerk wurden die Dokumente eines Korpus anhand ihrer Topics verbunden. die Stärke der Linie zwischen den Knoten gibt an 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/2-Hauptteil/semantic_network}
	\caption[Beispiel eines Netzwerks]{Beispiel eines Netzwerks}
\end{figure}

%Kritikpunkt ist die Polysemie Mehrdeutigkeit Vorhandensein mehrerer Bedeutungen bei einem Wort\cite[3]{Steyvers.2007} 
%Ein Resultat der Darstellung der Topic Models mit Standarddiagrammen ist die Notwendigkeit der Interaktivität aufgrund der Größe des analysierten Korpus.
%Einfache Darstellungsformen führen zu einer nicht unbedingt erhöhten Informationsgewinn durch die Topic Models. 
Eine solche Darstellung ist aber nicht einfach umzusetzen, aufgrund der hohen Abstraktion der Ergebnisse. Diese Ergebnisse lassen sich nur vollständig und kompakt darstellen, wenn eine interaktive Darstellungsform gewählt wird.\cite[1]{Sievert.2014}

Es wurden bereits eine Reihe von Verfahren entwickelt die sich grob in zwei Gruppen einteilen lassen. Diese Gruppen unterscheiden sich in der Zielsetzung die mit der Erstellung des Topic Models verfolgt wird.
Eine Anzahl von Systemen zur Visualisierung von Topic Models wurden in den letzten Jahren entwickelt. Einige von ihnen sind auf das Ermöglichen des Anwenders fokussiert, Dokumente, Topics und Wörter durchzusehen um etwas über die Beziehung zwischen diesen drei Basiseinheiten herauszufinden \cite[65]{Sievert.2014}
Die erste Gruppe verwendet Topic Models um eine Sammlung von Texten zu  visualisieren und die zweite ermöglicht die Suche nach Dokumenten zu bestimmten Themen. Bei der ersten Gruppe werden die Topics, ähnlich wie in einem Netzwerk in einem zweidimensionalen Raum dargestellt.Die zweite Gruppe verwendet die Topic Models um eine Sammlung von Dokumenten in ihre Themen aufzuteilen und diese Dokumente mit anderen Themen bzw. Dokumenten zu verknüpfen. Bei den letzteren Verfahren spricht man allgemein auch von Topic Browsern, da sie das Browsen durch eine Sammlung von Dokumenten ermöglichen. 

\paragraph{Online verfügbare Verfahren}
\label{sec:online_verf_verfahren}
Dieser Abschnitt enthält eine Liste an Internetreferenzen zu Projekten die sich mit der Darstellung von Topic Models befasst haben
\begin{itemize}
	\item The networked corpus
		\\http://www.networkedcorpus.com/
		\\https://github.com/jeffbinder/networkedcorpus
		\\http://ach.org/2013/12/30/cultures-of-visualization-adam-smiths-index-and-topic-modeling/

	\item jsLDA
		\\http://mimno.infosci.cornell.edu/jsLDA/
		\\http://mimno.infosci.cornell.edu/

	\item Structural Topic Models
		\\http://structuraltopicmodel.com/
		\\https://github.com/mroberts/stmBrowser

	\item journal topic-model browser Jonathan Goodwin
		\\http://jgoodwin.net/theory-browser/
		\\http://jgoodwin.net/categories/quantitative-methods/

	\item dfr-browser
		\\https://agoldst.github.io/dfr-browser/

	\item TOME
		\\http://dhlab.lmc.gatech.edu/tome/

	\item http://christo.cs.umass.edu/wiki40/

	\item http://christo.cs.umass.edu/classics-wiki/

\end{itemize}

Exemplarisch für die zwei Gruppen von Verfahren sollen im in den folgenden zwei Teilen. Zwei Projekte vorgestellt werden, die eine robuste Realisierung der jeweiligen Anwendung darstellen. 


\subsection{LDAvis}
\label{sec:LDAvis}

Das LDAvis Verfahren ist die Weiterentwicklung von Systemen, die bereits zur Visualisierung von Topic Models erstellt wurden. Das System soll grundlegende Fragen wie (1) Was ist die Bedeutung eines Topics?, (2) Wie weit verbreitet ist ein Topic?, und (3) Was ist die Verbindung zwischen den Topics? 
\\Abbildung 2.5 zeigt eine beispielhafte Visualisierung eines Topic Models mit dem LDAvis System. Die linke Seite der Abbildung stellt den globalen Zusammenhang im Topic Model dar. Sie beanwortet die Fragen 2 und 3. In dieser Ansicht werden die Topics als Kreise in einem zweidimensionalen Raum dargestellt. Der Abstand wird wie in dem Artikel von Chuang\cite{Chuang.2012b} berechnet. Der gesamt Anteil eines Topics am Korpus wird über die Fläche des Kreises dargestellt. 
\\Auf der rechten Seite werden die Wörter, die am nützlichsten für die Interpretation des ausgewählten Topics sind angezeigt. Die rechte Seite gibt somit Aufschluss über die Bedeutung der einzelnen Topics. Die übereinanderliegenden Balken codieren die Häufigkeit des Worts im Korpus beziehungsweise im jeweiligen Topic. Die Berechnung der Topic spezifischen Häufigkeit erfolgt, wie im wie im Termite Browser von Chuang\cite{Chuang.2012}. 
Die rechte und die linke Seite sind verbunden und interaktiv. Wählt man ein Topic auf der linken Seite aus, erhält man die zugehörigen Wörter auf der rechten Seite. Umgekehrt erhält man bei der Auswahl eines Wortes auf der rechten Seite dessen Verteilung über die Themen auf der linken Seite.
\\Das LDAvis System implementiert eine neue Methode um die nützlichsten Wörter für die Interpretation zu finden und zu sortieren. Die Autoren stellen eine Kennzahl für die Wörter vor, die Sie die Relevanz des Wortes nennen.\cite[63]{Sievert.2014} 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{images/2-Hauptteil/LDAvis_example}
	\caption[Beispiel für das LDAvis]{Abbildung des LDAvis: 	Die Grafik ist dem Beispiel auf der Webseite				\footnote{https://cpsievert.github.io/LDAvis/reviews/		vis/} des LDAvis entnommen. Mit \#topic=k\&lambda=l			\&term=s lässt sich ein Wert für das Topic, lambda und 		den Term festlegen}
\end{figure}

Relevanz der Wörter für die Topics und die Studie
Wie bereits beschrieben, steht $\Phi_{kw}$ im LDA Topic Model für die Wahrscheinlichkeit des Terms $w \in \lbrace1,\ldots,V\rbrace$ für das Topic $k \in \lbrace1,\ldots,K\rbrace$ und $p_w$ steht für die Wahrscheinlichkeit des Terms $w$ im Korpus. Die Relevanz $r$ eines Terms $w$ für ein Topic $k$ wird definiert als:

\begin{equation}	
	r\left(w,k|\lambda\right) = \lambda log\left(\Phi_{kw}		\right) + (1-\lambda)log\left(\frac{\Phi_{kw}}{p_{w}}		\right),
\end{equation}

Die Gleichung setzt sich aus den gewichteten und  logarithmierten Größen für die Wahrscheinlichkeit $\Phi_{kw}$ und dem Lift zusammen. Die Gewichtung erfolgt durch den Parameter $\lambda \left(wobei 0\le \lambda \le 1\right)$. Wird für $\lambda$ der Wert 1 verwendet, erhält man das gewohnte Ranking der Wörter nur nach den Wahrscheinlichkeiten, des LDA. Ist $\lambda = 0$ dann erfolgt das Ranking ausschließlich auf der Grundlage des Lifts\cite[66]{Sievert.2014}.
\\Der Lift ist das Verhältnis der Wahrscheinlichkeit eines Terms $w$ für ein Topic $k$ und der Wahrscheinlichkeit eines Wortes im Korpus $p_w$. Diese Kennzahl stammt ursprünglich von Taddy \cite{Taddy.2011}. 
\\Um herauszufinden, ob es ein optimalen Wert für $\lambda$ gibt führten die Autoren eine Studie mit Anwendern durch. Die Aufgabe der Teilnehmer war, eine Liste mit fünf nach ihrer Relevanz geordneten Wörter zu lesen und der Liste eines von drei vorgeschlagenen Topics zuzuordnen. Die Werte für $\lambda$ wurden zufällig ausgewählt. Die Ergebnisse waren, dass der optimale Wert für $\lambda$ bei ungefähr 0.6 und die Wahrscheinlichkeit einer richtigen zu Ordnung des Topics von circa 70\%. Werte für $\lambda$ nahe 0 und 1 führten nur zu Wahrscheinlichkeiten von 53\% und 63\%. 

The LDAvis system

Voraussetzungen der Anwendung
%details Pdf zum LDAvis

\footnote{https://cran.r-project.org/web/packages/LDAvis/LDAvis.pdf}

Pythonimplementierung von LDAvis

\footnote{https://pypi.python.org/pypi/pyLDAvis/1.0.0}

\subsection{Topic Browser}
\label{sec:Topic Browser}

Darstellung und zugriff auf den Korpus durch die einzelnen Topics. Speziell die Verbindung von Topic, Dokument und den verwandten Topics. 

Auch wenn diese Werkzeuge hilfreich sind, wenn man eine Sammlung von Texten durcharbeiten möchte, suchen wir eine kompaktere Visualisierung, mit einem Fokus auf dem schnellen und einfachen verstehen von einzelnen Topics ohne zwangsläufig die Dokumente darzustellen\cite[65]{Sievert.2014}

Zusammenfassung des Artikels
\begin{enumerate}
	\item Einleitung
		\begin{itemize}
			\item Das Verstehen und Navigieren durch große 				Dokumente ist eine wichtige Aktivität in vielen 			Bereichen
			\item Umfangreiche Dokumente lassen sich nur 				schwer von Hand organisieren, weshalb eine 					Automatisierung des Prozesses nötig ist.
			\item Topic Model Algorithmen finden unbekannte 			Themenstrukturen in Dokumenten. Das Ergebnis 				der Topic Models ist allerdings nur unter hohem 			Aufwand analysierbar, da die Ergebnisse in Form 			von Zahlen vorliegen
			\item Wir schlagen ein angepasstes Topic Model 				vor, um einen Corpus zu organisieren, 						visualisieren, zusammmenzufassen und mit ihm zu 			interagieren.
			\item Die entdeckte Struktur legt Beziehungen 				offen, die zu Interaktionen in der 							Visualisierung führen
			\item Die Ziele sind daher: Den Corpus 						zusammmenzufassen, Beziehungen zwischen Inhalt 				und Zusammenfassungen aufzudecken und 						Beziehungen im Inhalt aufzudecken
		\end{itemize}				

	\item In Verbindung stehende Literatur
		\begin{itemize}
			
			\item Um den Corpus als ganzes zu verstehen 				bieten sich folgende Ansätze an: Exemplar-based 			Visualization, der ThemeRiver und der 						FacetAtlas
			\item Die von uns entwickelte Visualisierung 				bietet eine kompakte Zusammenfassung des Corpus 			und Verbindungen zwischen der Zusammenfassung 				und den individuellen Dokumenten
			\item Vorausgehende Forschung zu Topic Models 				fokussierte sich auf die Verbesserung der 					Algorithmen und bedienten sich zur Darstellung 				an Browsern.
			\item Diese Browser heben Topics hervor und 				beachten die Dokumente nur wenig.
		\end{itemize}		
	\item Probabilistic Topic Models
		\begin{itemize}
			\item Der Ansatz beschränkt sich auf dne latent 			Dirichlet allocation (LDA) Algorithmus, einem 				der einfachsten probabilistischen topic model. 
			\item Der LDA Algorithmus zerlegt eine Menge an 			Dokumenten in Topics und stellt jedes Dokument 				mit einem gewichteten subset der Topics dar. 
			\item Grober Algorithmus des LDA
		\end{itemize} 

\item Visualisierung eines Topic Models
		\begin{itemize}

			\item Die Visualisierung verwendet sowohl die 				originalen Daten des Corpus als auch die 					abgeleiteten Variablen der Topic Model.
			\item Bei den Topic Model Variablen handelt es 				sich um die Topics beta k, die jeweils eine 				Verteilung über das Vokabular darstellen und 				das Verhältnis der Topics, eine für jedes 					Dokument, welche eine Verteilung über die 					Topics ist.
		\end{itemize} 
\item Visualisieren der Elemente des Topic Models
	\begin{itemize}

		\item Der Navigator besitzt zwei Hauptseiten: eine 			für die Darstellung der entdeckten Topics und eine 			andere für die Dokumente. Des weiteren gibt es eine 		Übersichtsseite, die die Struktur des Corpus 				darstellt.
	\end{itemize}
\begin{enumerate}

\item Topic Pages
\begin{itemize}
\item Topics fassen den Corpus zusammen. Im Output eines Inferenz Algorithmus sind Sie die Wahrscheinlichkeitsverteilung über das Vokabular. 
\item In dieser Darstellung werden die Wörter in einer Liste auf der linken Seite dargestellt, wobei das wahrscheinlichste Wort an erster Stelle steht. Geordnet nach ihrer topic term probability
\item In der mittleren Spalte ist eine Liste an Dokumenten, die dieses Topic umfassen, geordnet nach dem Verhältnis der Topics. Die Titel enthalten eine Verlinkung zu den entsprechenden Dokumenten
\item Verwandte Topics werden in der rechten Spalte aufgeführt. Geordnet nach ihrer pairwise topic dissimilarity score. Siehe Ausdruck. Diese Kennzahl findet Topics mit einer ähnlichen Verteilung.
\end{itemize}	
	
\item Document Pages
\begin{itemize}
\item Die Dokumenten Seiten stellen den originalen Corpus dar. Dort werden die Dokumente und die topics, die das Dokument darstellt, geordnet nach dem Verhältnis der topics. 
\item Die Dokumente werden auch mit ähnlichen Dokumenten verbunden. Dazu wird eine Kennzahl ähnlich der pairwise dissimilarity score berechnet. Allerdings wird das Verhältnis der Topics als Grundlage für die Berechnung verwendet. Diese Kennzahl gibt Auskunft, wie ähnlich sich zwei Dokumente sind. 
\end{itemize}		
		 
\item Overview Pages
\begin{itemize}
\item Die Overview Pages sind der Einstiegspunkt zur Erkundung des Corpus. Auf der Seite werden die Topics anhand ihrer Häufigkeit im Corpus dargestellt. Die Häufigkeit eines Topics ist die Summe aller Verhältnisse in allen Dokumenten. 
\end{itemize}		
\end{enumerate}

\item Implementierung 
\begin{itemize}
\item Um die Methode für die Visualisierung zu nutzen sind drei Schritte nötig.
\begin{enumerate}
\item Den LDA Algorithmus auf einen Corpus anwenden um die Wahrscheinlichkeiten der versteckten Variablen zu erhalten. 
\item Eine Datenbank erstellen
\item Webseiten erstellen um durch den Corpus zu navigieren. 
\end{enumerate}	
\end{itemize}
\end{enumerate}

\chapter{Anwendung}
\label{sec:Anwendung}

\section{Topic Models mit dem LDA Verfahren}
\label{sec:ergebnisse_des_LDA}
Um die Topic Models visualisieren zu können muss zunächst ein Topic Model von einem Korpus erstellt werden. Die Schritte, die nötig sind um ein Topic Model zu erstellen sind die folgenden. Zunächst muss ein Korpus ausgewählt werden. Dieser Korpus muss in weiteren Schritten aufbereitet werden. Diese Schritte sind kritisch für die Qualität des daraus folgenden Topic Models. 
Zu diesen Schritten gehören folgende: 
\begin{itemize}
	\item Erstellung des Korpus
	\item Entfernung der Stopwörter 
	\item Entfernung seltener Wörter
	\item Erstellung des Vokabulars
	
\end{itemize}
Da es sich dabei nicht um den Schwerpunkt der Arbeit handelt verwende Ich das Beispiel auf der Seite der gensim Bibliothek. Die Gensim Bibliothek umfasst vorgefertigte Skripte die die Erstellung von Topic Models zu der englischen Wikipedia ermöglichen. Die mitgelieferten Skripte übernehmen das gesamte Preprocessing der Daten. 

Eine vergleichbares Projekt von Mimno hat den Wikipedia Korpus in 500 Topics aufgeteilt. 

Die Ergebnisse meines Topic Models
\newpage

\section{Visualisierung des Topic Models}
\label{sec:visualisierung_topicmodels}
\newpage

\subsection{Topic Models als Netzwerk}
\label{sec:networks}
\newpage

\subsection{Erstellung eines Topic Browsers}
\label{sec:erstellung_TopicBrowser}
\newpage

\subsection{Visualisierung mit LDAvis}
\label{sec:anwendung_LDAvis}
\newpage